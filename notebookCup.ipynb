{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import NetCup\n",
    "import LoadDataCup\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as display\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "print(\"TRAINING CUP DATASET\")\n",
    "# HYPERPARAMETER\n",
    "#interval = 0.7\n",
    "learning_rate = 0.0008\n",
    "num_epochs = 1000\n",
    "momentum = 0.9\n",
    "threshold = 0.1\n",
    "\n",
    "#grid search\n",
    "layers1 = [72, 100, 128, 156, 184, 212, 240]\n",
    "layers2 = [100, 128, 156, 184, 212, 240, 256, 284, 312]\n",
    "layers3 = [32, 54, 64, 72, 90]\n",
    "\n",
    "\n",
    "for layer1, layer2, layer3 in product(layers1, layers2, layers3):\n",
    "    # PATH\n",
    "    pathTrain = \"CUP/ML-CUP23-TRAIN.csv\"\n",
    "    pathTestInput = \"CUP/ML-CUP23-TEST-INPUT.csv\"\n",
    "    pathTestTarget = \"CUP/ML-CUP23-TEST-TARGET.csv\"\n",
    "    pathName = f'modelsCup/Cup-{layer1}-{layer2}-{layer3}'\n",
    "    # IMPORT DATA\n",
    "    dataCup = LoadDataCup.DataCup(pathTrain, pathTestInput, pathTestTarget)\n",
    "    # SPLIT SET\n",
    "    dataCup.splitData()\n",
    "    # DATA: TENSOR, GPU, DATALOADER\n",
    "    dataCup.convertToTensor()\n",
    "    dataCup.moveToGpu()\n",
    "    data_loader_train, data_loader_test = dataCup.createDataLoader()\n",
    "    # CREATE NET\n",
    "    # If you need to change the neurons number go to netCup.py\n",
    "    print(\"Load regressor [net]\")\n",
    "    net = NetCup.NetCupRegressor(layer1, layer2, layer3)\n",
    "    #net = NetCup.NetCupCNN()\n",
    "    # MOVE NET TO GPU\n",
    "    net = net.to(\"cuda:0\")\n",
    "    # SET TYPE NET\n",
    "    net = net.double()\n",
    "    # OPTIMIZER AND CRITERION\n",
    "    # MSELoss for Regressor\n",
    "    # SGD for Regressor\n",
    "    print(\"Load MSELoss [criterion]\\nLoad SGD [optimizer]\")\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "    # CREATE DIR\n",
    "    os.makedirs(pathName, exist_ok=True)    \n",
    "\n",
    "    # MODEL SAVE\n",
    "    \"\"\"\n",
    "    with open(f'{pathName}/model_parameters.txt', 'w') as file:\n",
    "        file.write('Pesi layer1\\n')\n",
    "        file.write(str(net.layer1.weight.data) + '\\n')\n",
    "        file.write('Bias layer1\\n')\n",
    "        file.write(str(net.layer1.bias.data) + '\\n')\n",
    "        file.write('Pesi layer2\\n')\n",
    "        file.write(str(net.layer2.weight.data) + '\\n')\n",
    "        file.write('Bias layer2\\n')\n",
    "        file.write(str(net.layer2.bias.data) + '\\n')\n",
    "        file.write('Pesi layer3\\n')\n",
    "        file.write(str(net.layer3.weight.data) + '\\n')\n",
    "        file.write('Bias layer3\\n')\n",
    "        file.write(str(net.layer3.bias.data) + '\\n')\n",
    "        file.write('Pesi layer4\\n')\n",
    "        file.write(str(net.layer4.weight.data) + '\\n')\n",
    "        file.write('Bias layer4\\n')\n",
    "        file.write(str(net.layer4.bias.data) + '\\n')\n",
    "    \"\"\"\n",
    "    #Values used for graphs\n",
    "    loss_values_train = []\n",
    "    accuracy_values_train = []\n",
    "    loss_values_test = []\n",
    "    accuracy_values_test = []\n",
    "    # BEST\n",
    "    best_accuracy_train = 0.0\n",
    "    best_accuracy_test = 0.0\n",
    "    #\n",
    "    results = []\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        for batch_input, batch_output in data_loader_train:\n",
    "            #Forward pass\n",
    "            outputs = net(batch_input)\n",
    "            #Training loss\n",
    "            loss = criterion(outputs, batch_output)\n",
    "            #Calculate total loss\n",
    "            total_loss += loss.item()\n",
    "            #Backward and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #\n",
    "            difference = torch.abs(outputs - batch_output)\n",
    "            total += batch_input.size(0)\n",
    "            correct += torch.sum(difference < threshold)\n",
    "        accuracy_train = correct / total\n",
    "        avg_loss_train = total_loss / len(data_loader_train)\n",
    "        #Add to list\n",
    "        loss_values_train.append(avg_loss_train)\n",
    "\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        #CALCULATE ACCURACY VAL\n",
    "        net.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_input, batch_output in data_loader_test:\n",
    "                outputs = net(batch_input)\n",
    "                loss = criterion(outputs, batch_output)\n",
    "                total_loss += loss.item()\n",
    "                difference = torch.abs(outputs - batch_output)\n",
    "                total += batch_input.size(0)\n",
    "                correct += torch.sum(difference < threshold)\n",
    "            accuracy_test = correct / total\n",
    "            avg_loss_test = total_loss / len(data_loader_test)\n",
    "            loss_values_test.append(avg_loss_test)\n",
    "        net.train()\n",
    "        \n",
    "        result = f'Epoch[{epoch+1}/{num_epochs}] Learning-rate: {learning_rate}, Loss-Train: {avg_loss_train:.4f}, Loss-Test: {avg_loss_test:.4f}, Best-Accuracy-Train: {accuracy_train:.4f}, Best-Accuracy-Test: {accuracy_test:.4f}'\n",
    "        print(result)\n",
    "        \n",
    "        #Set best accuracy\n",
    "        best_accuracy_train = max(best_accuracy_train, accuracy_train)\n",
    "        best_accuracy_test = max(best_accuracy_test, accuracy_test)\n",
    "        \n",
    "        #List append\n",
    "        accuracy_values_train.append(accuracy_train.item())\n",
    "        accuracy_values_test.append(accuracy_test.item())\n",
    "        results.append(result)\n",
    "        \n",
    "\n",
    "    #Save model\n",
    "    torch.save(net, f'{pathName}/model.pth')\n",
    "\n",
    "    #Save plot loss\n",
    "    display.clear_output(wait=True)\n",
    "    plt.plot(loss_values_train, label='Training Loss')\n",
    "    plt.plot(loss_values_test, label = 'Test loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss per Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{pathName}/Loss.png')\n",
    "    plt.clf()\n",
    "\n",
    "    #Save plot accuracy\n",
    "    display.clear_output(wait=True)\n",
    "    plt.plot(accuracy_values_train, label='Accuracy Train')\n",
    "    plt.plot(accuracy_values_test, label='Accuracy Test')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy for Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{pathName}/Accuracy-test.png')\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    with open(f\"{pathName}/results.txt\", 'w') as file:\n",
    "        for res in results:\n",
    "            file.write(res + \"\\n\")\n",
    "        bestPrint = f\"Best-Accuracy-Train: {best_accuracy_train:.4f}, Best-Accuracy-Test: {best_accuracy_test:.4f}\"\n",
    "        file.write(bestPrint + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
